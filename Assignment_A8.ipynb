{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaQhcn8FVSAe"
      },
      "source": [
        "In this assignment, I will verify the results presented in the paper \"Do We Really Need Multiplications in Deep Learning?\" by replicating experiments on the CIFAR-10 dataset using VGG, ResNet-20, and ResNet-32 architectures. The focus will be on comparing three approaches: standard Convolutional Neural Networks (CNNs), Binary Neural Networks (BNNs), and Adder Networks (AdderNets).\n",
        "\n",
        "AdderNets, as proposed in the paper, replace the computationally expensive multiplications in CNNs with additions by using the â„“1-norm distance to compute similarity between input features and filters, significantly reducing the computational complexity. I will evaluate the performance of these models, with a particular focus on verifying accuracy and computational cost reductions claimed by AdderNets.\n",
        "\n",
        "The goal is to replicate and confirm the findings from the original research, which demonstrated that AdderNets could achieve competitive accuracy without the need for multiplication-heavy operations in deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment A8: CIFAR-10 Dataset Overview\n",
        "\n",
        "In this assignment, I will be using the CIFAR-10 dataset, which consists of\n",
        " 60,000 color images of size 32x32, divided into 10 classes. Each class contains 6,000 images, making the dataset a diverse collection for image classification tasks.\n",
        "\n",
        "The dataset is split into two primary sections:\n",
        "50,000 training images\n",
        "10,000 test images\n",
        "\n",
        "The training set is further divided into five batches, each containing 10,000 image. These batches are organized in a random order, meaning that some classes may appear more frequently in certain batches than others. However, the total number of images per class across all training batches is evenly distributed, with 5,000 images per class.\n",
        "\n",
        "The test set consists of one batch of 10,000 images, with exactly 1,000 images randomly selected from each class.\n",
        "\n",
        "The 10 classes in the dataset are as follows:\n",
        "1. Airplane\n",
        "2. Automobile\n",
        "3. Bird\n",
        "4. Cat\n",
        "5. Deer\n",
        "6. Dog\n",
        "7. Frog\n",
        "8. Horse\n",
        "9. Ship\n",
        "10. Truck"
      ],
      "metadata": {
        "id": "MeMvn8ecyXCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Pytorch Libraries"
      ],
      "metadata": {
        "id": "PqCrrGQ1zMAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcckZSy2-gMB",
        "outputId": "a9a64fe7-c623-498b-d3df-c40a55d906b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZISZHP0g49EE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-bISplpAE25"
      },
      "outputs": [],
      "source": [
        "# Set device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG-Small Architecture"
      ],
      "metadata": {
        "id": "YEUI6_INOf6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGScratch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGScratch, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)  # CIFAR-10 has 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output from conv layers\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "1uLMmrx9Oe4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = VGGScratch().to(device)\n"
      ],
      "metadata": {
        "id": "V4GKPPxaO7VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n"
      ],
      "metadata": {
        "id": "Y4cgsqHLO_4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsCgY-SPPC4u",
        "outputId": "6cff6729-55e7-4faa-88a3-a050a131058a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "DQH0TLwEPHPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "buRbXEHMPL1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear previous gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass (calculate gradients)\n",
        "            optimizer.step()  # Update weights using gradients\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "_CWm4jLdPP-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "d6EgaxxhPU_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYG0WppePcAo",
        "outputId": "156f62be-23b6-44f4-8529-0ea3c230051b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.2601\n",
            "Epoch [2/10], Loss: 1.0624\n",
            "Epoch [3/10], Loss: 0.9208\n",
            "Epoch [4/10], Loss: 0.8009\n",
            "Epoch [5/10], Loss: 0.7105\n",
            "Epoch [6/10], Loss: 0.6459\n",
            "Epoch [7/10], Loss: 0.5977\n",
            "Epoch [8/10], Loss: 0.5547\n",
            "Epoch [9/10], Loss: 0.5190\n",
            "Epoch [10/10], Loss: 0.4919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-69np0yQAHm",
        "outputId": "6c4853b6-2f5a-418e-b723-3d23eae9ce9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here VGGS-small architechture was trained  that achieved  82.78% accuracy with standard CNN  on 10 epochs"
      ],
      "metadata": {
        "id": "c-3mMnQyzxCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 20  with CNN"
      ],
      "metadata": {
        "id": "OJveP1nM0UXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet20(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet20, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(16, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(32, 3, stride=2)\n",
        "        self.layer3 = self._make_layer(64, 3, stride=2)\n",
        "        self.fc = nn.Linear(64, 10)  # CIFAR-10 has 10 classes\n",
        "\n",
        "    def _make_layer(self, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = nn.AvgPool2d(8)(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "0zSG9_ql7-i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = ResNet20().to(device)\n"
      ],
      "metadata": {
        "id": "epPIygBV8Ajt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n"
      ],
      "metadata": {
        "id": "dphi6vEv8HwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRTwgoa18HkL",
        "outputId": "ee56eb66-6c87-4ee2-b672-754510c73b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "snS1pKDQ8HVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "mc65378C8G7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear previous gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass (calculate gradients)\n",
        "            optimizer.step()  # Update weights using gradients\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "IOLRBgp28BlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "9INNW7l18BjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model()\n",
        "\n",
        "# Test the model\n",
        "test_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aHN3Mw-8Bev",
        "outputId": "142f0049-f7c8-4b78-f19a-14596a39a0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.4981\n",
            "Epoch [2/10], Loss: 1.0445\n",
            "Epoch [3/10], Loss: 0.8584\n",
            "Epoch [4/10], Loss: 0.7513\n",
            "Epoch [5/10], Loss: 0.6757\n",
            "Epoch [6/10], Loss: 0.6340\n",
            "Epoch [7/10], Loss: 0.5901\n",
            "Epoch [8/10], Loss: 0.5706\n",
            "Epoch [9/10], Loss: 0.5434\n",
            "Epoch [10/10], Loss: 0.5264\n",
            "Accuracy: 79.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here Resnet-20 was trained and achieved 79.52%  accuracy with Standard CNN layers  that is lower compare to Vgg-small"
      ],
      "metadata": {
        "id": "HUO8s_V90yBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 32 with Cnn layers"
      ],
      "metadata": {
        "id": "5qM8GDf3OmEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet32(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet32, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(16, 5, stride=1)\n",
        "        self.layer2 = self._make_layer(32, 5, stride=2)\n",
        "        self.layer3 = self._make_layer(64, 5, stride=2)\n",
        "        self.fc = nn.Linear(64, 10)  # CIFAR-10 has 10 classes\n",
        "\n",
        "    def _make_layer(self, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = nn.AvgPool2d(8)(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "y32duYFi-r4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet32().to(device)\n"
      ],
      "metadata": {
        "id": "7tMDW6a9-r25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n"
      ],
      "metadata": {
        "id": "TubsH8am-rt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOrC9roe-rrh",
        "outputId": "23aa4c41-1f56-4983-b2cf-a7e3ed64760b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "LEumttXz-rcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "XGhvnTdB-rVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_model():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear previous gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass (calculate gradients)\n",
        "            optimizer.step()  # Update weights using gradients\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "OyZws3T--rTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "l1K_0O4_-rMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model()\n",
        "\n",
        "# Test the model\n",
        "test_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-w7NlAb-rKq",
        "outputId": "27d0f44f-672b-427a-f424-ad1d4082ce52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.6043\n",
            "Epoch [2/10], Loss: 1.0623\n",
            "Epoch [3/10], Loss: 0.8432\n",
            "Epoch [4/10], Loss: 0.7356\n",
            "Epoch [5/10], Loss: 0.6627\n",
            "Epoch [6/10], Loss: 0.6122\n",
            "Epoch [7/10], Loss: 0.5775\n",
            "Epoch [8/10], Loss: 0.5466\n",
            "Epoch [9/10], Loss: 0.5242\n",
            "Epoch [10/10], Loss: 0.4985\n",
            "Accuracy: 81.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Resnet-32  I achieved 81.78% with CNN  with 10 epochs"
      ],
      "metadata": {
        "id": "2tklLuR51t89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The standard convolutional(CNN) in VGGsmall are replaced by adder layers to reduce energy consumption during training.\n",
        "\n",
        "# CNN (Convolutional Neural Network) layers perform feature extraction by applying a convolution operation,\n",
        "# which involves element-wise multiplication between the input feature map and the filter (kernel), followed by summation.\n",
        "# This multiplication-heavy operation is energy-expensive.\n",
        "#\n",
        "# AdderNet replaces the convolution operation by using addition-based operations.\n",
        "# Instead of performing element-wise multiplication, AdderNet computes the absolute difference between the input and filter weights:\n",
        "#\n",
        "# AdderNet Operation: |Input - Filter|\n",
        "#\n",
        "# The result is then summed to produce the output feature map. This approach reduces energy consumption by avoiding\n",
        "# costly multiplication operations, using addition instead, which is more efficient.\n",
        "#\n",
        "# How it compares to CNN:\n",
        "# In CNN: Output = summation (Input * Filter) + Bias\n",
        "# In AdderNet: Output = summation |Input - Filter| + Bias\n",
        "#\n",
        "# By replacing the CNN layers with AdderNet, the energy efficiency of the network increases, while still preserving the\n",
        "# hierarchical structure and overall architecture of VGGsmall.\n",
        "#\n",
        "# AdderNet also supports backpropagation, where the partial derivatives during training are computed by taking the gradient\n",
        "# of the L1 norm (|Input - Filter|), which is the sign of the difference. The gradient is then used to update the weights:\n",
        "#\n",
        "# Gradient (w.r.t weights) = sign(Input - Filter)\n",
        "#\n",
        "# This allows AdderNet to work seamlessly with gradient-based optimization methods (e.g., SGD, Adam),\n",
        "# ensuring proper weight updates and network training.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sWV1e689CVGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet-20 with Addernet layers"
      ],
      "metadata": {
        "id": "9q7la5t05aBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "import math"
      ],
      "metadata": {
        "id": "OB58J43JASp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define AdderNet Convolution Layer\n",
        "def adder2d_function(X, W, stride=1, padding=0):\n",
        "    n_filters, d_filter, h_filter, w_filter = W.size()\n",
        "    n_x, d_x, h_x, w_x = X.size()\n",
        "\n",
        "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
        "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
        "\n",
        "    h_out, w_out = int(h_out), int(w_out)\n",
        "    X_col = torch.nn.functional.unfold(X.view(1, -1, h_x, w_x), h_filter, dilation=1, padding=padding, stride=stride).view(n_x, -1, h_out*w_out)\n",
        "    X_col = X_col.permute(1,2,0).contiguous().view(X_col.size(1),-1)\n",
        "    W_col = W.view(n_filters, -1)\n",
        "\n",
        "    out = adder.apply(W_col,X_col)\n",
        "\n",
        "    out = out.view(n_filters, h_out, w_out, n_x)\n",
        "    out = out.permute(3, 0, 1, 2).contiguous()\n",
        "\n",
        "    return out\n",
        "\n",
        "class adder(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, W_col, X_col):\n",
        "        ctx.save_for_backward(W_col,X_col)\n",
        "        output = -(W_col.unsqueeze(2)-X_col.unsqueeze(0)).abs().sum(1)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx,grad_output):\n",
        "        W_col,X_col = ctx.saved_tensors\n",
        "        grad_W_col = ((X_col.unsqueeze(0)-W_col.unsqueeze(2))*grad_output.unsqueeze(1)).sum(2)\n",
        "        grad_W_col = grad_W_col/grad_W_col.norm(p=2).clamp(min=1e-12)*math.sqrt(W_col.size(1)*W_col.size(0))/5\n",
        "        grad_X_col = (-(X_col.unsqueeze(0)-W_col.unsqueeze(2)).clamp(-1,1)*grad_output.unsqueeze(1)).sum(0)\n",
        "\n",
        "        return grad_W_col, grad_X_col\n",
        "\n",
        "class adder2d(nn.Module):\n",
        "    def __init__(self, input_channel, output_channel, kernel_size, stride=1, padding=0, bias=False):\n",
        "        super(adder2d, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.adder = torch.nn.Parameter(nn.init.normal_(torch.randn(output_channel, input_channel, kernel_size, kernel_size)))\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.b = torch.nn.Parameter(nn.init.uniform_(torch.zeros(output_channel)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = adder2d_function(x, self.adder, self.stride, self.padding)\n",
        "        if self.bias:\n",
        "            output += self.b.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
        "        return output\n",
        "\n",
        "#Basic Block for ResNet-20\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = adder2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = adder2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                adder2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# ResNet-20 with AdderNet Layers\n",
        "class ResNet20(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet20, self).__init__()\n",
        "       self.in_channels = 16\n",
        "        self.conv1 = adder2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Data Preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize Model, Loss Function, Optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet20(BasicBlock, [3, 3, 3]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training Function\n",
        "def train_model(num_epochs=4):  # 4 num of ephochs due to long processing and limited access to GPU\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision forward and backward pass\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)  # Forward pass\n",
        "                loss = criterion(outputs, labels)  # Compute loss\n",
        "\n",
        "            scaler.scale(loss).backward()  # Backward pass\n",
        "            scaler.step(optimizer)  # Update weights\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if i % 100 == 99:  # Print every 100 mini-batches\n",
        "                print(f\"Batch [{i + 1}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
        "        test_model()\n",
        "\n",
        "# Testing Function\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # No gradient calculation in evaluation\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Train and Evaluate\n",
        "train_model(num_epochs=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68K4s234ASl4",
        "outputId": "647b5ec8-ec63-4075-f297-f5ec2eb95cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-25b96a4cae97>:137: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-8-25b96a4cae97>:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch [100], Loss: 2.3178\n",
            "Batch [200], Loss: 2.2841\n",
            "Batch [300], Loss: 2.2990\n",
            "Batch [400], Loss: 2.1874\n",
            "Batch [500], Loss: 2.2778\n",
            "Batch [600], Loss: 2.2192\n",
            "Batch [700], Loss: 2.2866\n",
            "Batch [800], Loss: 2.1962\n",
            "Batch [900], Loss: 2.1501\n",
            "Batch [1000], Loss: 2.1495\n",
            "Batch [1100], Loss: 2.1741\n",
            "Batch [1200], Loss: 2.1797\n",
            "Batch [1300], Loss: 2.2517\n",
            "Batch [1400], Loss: 2.1338\n",
            "Batch [1500], Loss: 2.1837\n",
            "Epoch [1/4], Loss: 2.2448\n",
            "Accuracy: 22.87%\n",
            "Batch [100], Loss: 1.8841\n",
            "Batch [200], Loss: 2.1563\n",
            "Batch [300], Loss: 2.0353\n",
            "Batch [400], Loss: 2.1056\n",
            "Batch [500], Loss: 1.9715\n",
            "Batch [600], Loss: 1.8636\n",
            "Batch [700], Loss: 1.8515\n",
            "Batch [800], Loss: 1.8632\n",
            "Batch [900], Loss: 1.9308\n",
            "Batch [1000], Loss: 1.7613\n",
            "Batch [1100], Loss: 1.7418\n",
            "Batch [1200], Loss: 1.8799\n",
            "Batch [1300], Loss: 2.0743\n",
            "Batch [1400], Loss: 1.6668\n",
            "Batch [1500], Loss: 1.6798\n",
            "Epoch [2/4], Loss: 1.9410\n",
            "Accuracy: 31.38%\n",
            "Batch [100], Loss: 1.8557\n",
            "Batch [200], Loss: 1.8150\n",
            "Batch [300], Loss: 1.6511\n",
            "Batch [400], Loss: 2.0561\n",
            "Batch [500], Loss: 1.8822\n",
            "Batch [600], Loss: 1.7124\n",
            "Batch [700], Loss: 1.9787\n",
            "Batch [800], Loss: 1.7389\n",
            "Batch [900], Loss: 1.4587\n",
            "Batch [1000], Loss: 1.6264\n",
            "Batch [1100], Loss: 1.8919\n",
            "Batch [1200], Loss: 1.7362\n",
            "Batch [1300], Loss: 2.1793\n",
            "Batch [1400], Loss: 1.8081\n",
            "Batch [1500], Loss: 1.9191\n",
            "Epoch [3/4], Loss: 1.7857\n",
            "Accuracy: 35.84%\n",
            "Batch [100], Loss: 1.9890\n",
            "Batch [200], Loss: 1.4807\n",
            "Batch [300], Loss: 1.7547\n",
            "Batch [400], Loss: 1.5580\n",
            "Batch [500], Loss: 1.5435\n",
            "Batch [600], Loss: 1.6541\n",
            "Batch [700], Loss: 1.7896\n",
            "Batch [800], Loss: 1.8572\n",
            "Batch [900], Loss: 1.7145\n",
            "Batch [1000], Loss: 1.8467\n",
            "Batch [1100], Loss: 1.7023\n",
            "Batch [1200], Loss: 1.5077\n",
            "Batch [1300], Loss: 1.6936\n",
            "Batch [1400], Loss: 1.5688\n",
            "Batch [1500], Loss: 1.8129\n",
            "Epoch [4/4], Loss: 1.7013\n",
            "Accuracy: 39.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "khU3PKA2ASje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG small Architecjture repalce with BNN"
      ],
      "metadata": {
        "id": "zqLalu-T-XRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Binarization function with straight-through estimator (STE)\n",
        "class BinaryActivation(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.sign()  # Binarize activations (output -1 or 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input.abs() > 1] = 0  # Gradient clipping for out of -1, 1 range\n",
        "        return grad_input\n",
        "\n",
        "# Binary convolutional layer\n",
        "class BinaryConv2d(nn.Conv2d):\n",
        "    def forward(self, input):\n",
        "        binary_weight = BinaryActivation.apply(self.weight)  # Binarize weights\n",
        "        return F.conv2d(input, binary_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "#  VGG-Small architecture using binary convolutions\n",
        "class BinaryVGGSmall(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(BinaryVGGSmall, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            BinaryConv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            BinaryConv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # 32x32 -> 16x16\n",
        "\n",
        "            BinaryConv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            BinaryConv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),  # 16x16 -> 8x8\n",
        "\n",
        "            BinaryConv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            BinaryConv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)   # 8x8 -> 4x4\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layers(x)\n",
        "        out = out.view(out.size(0), -1)  # Flatten the output\n",
        "        out = self.fc_layers(out)\n",
        "        return out\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomCrop(32, padding=4),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, trainloader, criterion, optimizer, device, epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100:.4f}')\n",
        "                running_loss = 0.0\n",
        "    print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "def test_model(model, testloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Setting up the device, model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BinaryVGGSmall().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training and testing the model\n",
        "train_model(model, trainloader, criterion, optimizer, device, epochs=20)\n",
        "test_model(model, testloader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE00FJ_MH3sU",
        "outputId": "a9879baa-dcfb-4e08-a3fb-8248fb2083be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Batch 100, Loss: 1.6066\n",
            "Epoch 1, Batch 200, Loss: 1.3004\n",
            "Epoch 1, Batch 300, Loss: 1.1341\n",
            "Epoch 2, Batch 100, Loss: 0.9064\n",
            "Epoch 2, Batch 200, Loss: 0.8814\n",
            "Epoch 2, Batch 300, Loss: 0.8344\n",
            "Epoch 3, Batch 100, Loss: 0.7314\n",
            "Epoch 3, Batch 200, Loss: 0.7037\n",
            "Epoch 3, Batch 300, Loss: 0.7092\n",
            "Epoch 4, Batch 100, Loss: 0.6321\n",
            "Epoch 4, Batch 200, Loss: 0.6277\n",
            "Epoch 4, Batch 300, Loss: 0.6284\n",
            "Epoch 5, Batch 100, Loss: 0.5742\n",
            "Epoch 5, Batch 200, Loss: 0.5827\n",
            "Epoch 5, Batch 300, Loss: 0.5497\n",
            "Epoch 6, Batch 100, Loss: 0.5174\n",
            "Epoch 6, Batch 200, Loss: 0.5120\n",
            "Epoch 6, Batch 300, Loss: 0.4956\n",
            "Epoch 7, Batch 100, Loss: 0.4752\n",
            "Epoch 7, Batch 200, Loss: 0.4585\n",
            "Epoch 7, Batch 300, Loss: 0.4809\n",
            "Epoch 8, Batch 100, Loss: 0.4373\n",
            "Epoch 8, Batch 200, Loss: 0.4219\n",
            "Epoch 8, Batch 300, Loss: 0.4345\n",
            "Epoch 9, Batch 100, Loss: 0.3969\n",
            "Epoch 9, Batch 200, Loss: 0.4082\n",
            "Epoch 9, Batch 300, Loss: 0.4208\n",
            "Epoch 10, Batch 100, Loss: 0.3789\n",
            "Epoch 10, Batch 200, Loss: 0.3833\n",
            "Epoch 10, Batch 300, Loss: 0.3913\n",
            "Epoch 11, Batch 100, Loss: 0.3521\n",
            "Epoch 11, Batch 200, Loss: 0.3653\n",
            "Epoch 11, Batch 300, Loss: 0.3573\n",
            "Epoch 12, Batch 100, Loss: 0.3228\n",
            "Epoch 12, Batch 200, Loss: 0.3346\n",
            "Epoch 12, Batch 300, Loss: 0.3371\n",
            "Epoch 13, Batch 100, Loss: 0.3202\n",
            "Epoch 13, Batch 200, Loss: 0.3180\n",
            "Epoch 13, Batch 300, Loss: 0.3244\n",
            "Epoch 14, Batch 100, Loss: 0.2938\n",
            "Epoch 14, Batch 200, Loss: 0.3162\n",
            "Epoch 14, Batch 300, Loss: 0.2956\n",
            "Epoch 15, Batch 100, Loss: 0.2746\n",
            "Epoch 15, Batch 200, Loss: 0.2700\n",
            "Epoch 15, Batch 300, Loss: 0.2844\n",
            "Epoch 16, Batch 100, Loss: 0.2612\n",
            "Epoch 16, Batch 200, Loss: 0.2648\n",
            "Epoch 16, Batch 300, Loss: 0.2746\n",
            "Epoch 17, Batch 100, Loss: 0.2337\n",
            "Epoch 17, Batch 200, Loss: 0.2531\n",
            "Epoch 17, Batch 300, Loss: 0.2571\n",
            "Epoch 18, Batch 100, Loss: 0.2417\n",
            "Epoch 18, Batch 200, Loss: 0.2350\n",
            "Epoch 18, Batch 300, Loss: 0.2541\n",
            "Epoch 19, Batch 100, Loss: 0.2232\n",
            "Epoch 19, Batch 200, Loss: 0.2322\n",
            "Epoch 19, Batch 300, Loss: 0.2359\n",
            "Epoch 20, Batch 100, Loss: 0.2078\n",
            "Epoch 20, Batch 200, Loss: 0.2096\n",
            "Epoch 20, Batch 300, Loss: 0.2259\n",
            "Finished Training\n",
            "Accuracy: 85.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet-20 architecture to use binary neural network (BNN) layers"
      ],
      "metadata": {
        "id": "XY6kcGNCBAzx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox4JSlc8q4zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4493e36f-b198-41a3-bcbc-cd9bb175d34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:03<00:00, 46962939.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Batch 100, Loss: 1.8599\n",
            "Epoch 1, Batch 200, Loss: 1.6155\n",
            "Epoch 1, Batch 300, Loss: 1.4806\n",
            "Epoch 2, Batch 100, Loss: 1.3016\n",
            "Epoch 2, Batch 200, Loss: 1.2432\n",
            "Epoch 2, Batch 300, Loss: 1.1835\n",
            "Epoch 3, Batch 100, Loss: 1.0854\n",
            "Epoch 3, Batch 200, Loss: 1.0463\n",
            "Epoch 3, Batch 300, Loss: 1.0211\n",
            "Epoch 4, Batch 100, Loss: 0.9542\n",
            "Epoch 4, Batch 200, Loss: 0.9517\n",
            "Epoch 4, Batch 300, Loss: 0.9197\n",
            "Epoch 5, Batch 100, Loss: 0.8778\n",
            "Epoch 5, Batch 200, Loss: 0.8462\n",
            "Epoch 5, Batch 300, Loss: 0.8111\n",
            "Epoch 6, Batch 100, Loss: 0.7845\n",
            "Epoch 6, Batch 200, Loss: 0.7687\n",
            "Epoch 6, Batch 300, Loss: 0.7933\n",
            "Epoch 7, Batch 100, Loss: 0.7534\n",
            "Epoch 7, Batch 200, Loss: 0.7334\n",
            "Epoch 7, Batch 300, Loss: 0.7334\n",
            "Epoch 8, Batch 100, Loss: 0.7106\n",
            "Epoch 8, Batch 200, Loss: 0.7101\n",
            "Epoch 8, Batch 300, Loss: 0.6864\n",
            "Epoch 9, Batch 100, Loss: 0.6857\n",
            "Epoch 9, Batch 200, Loss: 0.6651\n",
            "Epoch 9, Batch 300, Loss: 0.6540\n",
            "Epoch 10, Batch 100, Loss: 0.6480\n",
            "Epoch 10, Batch 200, Loss: 0.6313\n",
            "Epoch 10, Batch 300, Loss: 0.6516\n",
            "Epoch 11, Batch 100, Loss: 0.6166\n",
            "Epoch 11, Batch 200, Loss: 0.6099\n",
            "Epoch 11, Batch 300, Loss: 0.6174\n",
            "Epoch 12, Batch 100, Loss: 0.6101\n",
            "Epoch 12, Batch 200, Loss: 0.6042\n",
            "Epoch 12, Batch 300, Loss: 0.6031\n",
            "Epoch 13, Batch 100, Loss: 0.5887\n",
            "Epoch 13, Batch 200, Loss: 0.5977\n",
            "Epoch 13, Batch 300, Loss: 0.5683\n",
            "Epoch 14, Batch 100, Loss: 0.5508\n",
            "Epoch 14, Batch 200, Loss: 0.5705\n",
            "Epoch 14, Batch 300, Loss: 0.5688\n",
            "Epoch 15, Batch 100, Loss: 0.5448\n",
            "Epoch 15, Batch 200, Loss: 0.5496\n",
            "Epoch 15, Batch 300, Loss: 0.5692\n",
            "Epoch 16, Batch 100, Loss: 0.5377\n",
            "Epoch 16, Batch 200, Loss: 0.5632\n",
            "Epoch 16, Batch 300, Loss: 0.5433\n",
            "Epoch 17, Batch 100, Loss: 0.5285\n",
            "Epoch 17, Batch 200, Loss: 0.5422\n",
            "Epoch 17, Batch 300, Loss: 0.5290\n",
            "Epoch 18, Batch 100, Loss: 0.5174\n",
            "Epoch 18, Batch 200, Loss: 0.5166\n",
            "Epoch 18, Batch 300, Loss: 0.5188\n",
            "Epoch 19, Batch 100, Loss: 0.5056\n",
            "Epoch 19, Batch 200, Loss: 0.5068\n",
            "Epoch 19, Batch 300, Loss: 0.5198\n",
            "Epoch 20, Batch 100, Loss: 0.5111\n",
            "Epoch 20, Batch 200, Loss: 0.5029\n",
            "Epoch 20, Batch 300, Loss: 0.5097\n",
            "Finished Training\n",
            "Accuracy: 78.49%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Binarization function with straight-through estimator (STE)\n",
        "class BinaryActivation(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.sign()  # Binarize activations (output -1 or 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input.abs() > 1] = 0  # Gradient clipping for out of -1, 1 range\n",
        "        return grad_input\n",
        "\n",
        "# Binary convolutional layer\n",
        "class BinaryConv2d(nn.Conv2d):\n",
        "    def forward(self, input):\n",
        "        binary_weight = BinaryActivation.apply(self.weight)  # Binarize weights\n",
        "        return F.conv2d(input, binary_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "# Define the basic block used in ResNet\n",
        "class BinaryBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BinaryBasicBlock, self).__init__()\n",
        "        self.conv1 = BinaryConv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = BinaryConv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                BinaryConv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the ResNet-20 architecture\n",
        "class BinaryResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(BinaryResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = BinaryConv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# ResNet-20 configuration\n",
        "def BinaryResNet20():\n",
        "    return BinaryResNet(BinaryBasicBlock, [3, 3, 3])\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomCrop(32, padding=4),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, trainloader, criterion, optimizer, device, epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100:.4f}')\n",
        "                running_loss = 0.0\n",
        "    print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "def test_model(model, testloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Setting up the device, model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BinaryResNet20().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training and testing the model\n",
        "train_model(model, trainloader, criterion, optimizer, device, epochs=20)\n",
        "test_model(model, testloader, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResneT-20 achived 78.49% accuracy with Binary neural network"
      ],
      "metadata": {
        "id": "K5hLiGJ3_6b9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet-32 architecture with BNN layers\n"
      ],
      "metadata": {
        "id": "09POFdoNG4qz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxjVc2I5q4yE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6d1d5c-2152-4367-9386-76bc3b6dd7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Batch 100, Loss: 1.8724\n",
            "Epoch 1, Batch 200, Loss: 1.6050\n",
            "Epoch 1, Batch 300, Loss: 1.4680\n",
            "Epoch 2, Batch 100, Loss: 1.3020\n",
            "Epoch 2, Batch 200, Loss: 1.2225\n",
            "Epoch 2, Batch 300, Loss: 1.1503\n",
            "Epoch 3, Batch 100, Loss: 1.0799\n",
            "Epoch 3, Batch 200, Loss: 1.0290\n",
            "Epoch 3, Batch 300, Loss: 1.0049\n",
            "Epoch 4, Batch 100, Loss: 0.9182\n",
            "Epoch 4, Batch 200, Loss: 0.9000\n",
            "Epoch 4, Batch 300, Loss: 0.8815\n",
            "Epoch 5, Batch 100, Loss: 0.8286\n",
            "Epoch 5, Batch 200, Loss: 0.8235\n",
            "Epoch 5, Batch 300, Loss: 0.8298\n",
            "Epoch 6, Batch 100, Loss: 0.7723\n",
            "Epoch 6, Batch 200, Loss: 0.7665\n",
            "Epoch 6, Batch 300, Loss: 0.7593\n",
            "Epoch 7, Batch 100, Loss: 0.7254\n",
            "Epoch 7, Batch 200, Loss: 0.7166\n",
            "Epoch 7, Batch 300, Loss: 0.7102\n",
            "Epoch 8, Batch 100, Loss: 0.6939\n",
            "Epoch 8, Batch 200, Loss: 0.6772\n",
            "Epoch 8, Batch 300, Loss: 0.6808\n",
            "Epoch 9, Batch 100, Loss: 0.6566\n",
            "Epoch 9, Batch 200, Loss: 0.6396\n",
            "Epoch 9, Batch 300, Loss: 0.6595\n",
            "Epoch 10, Batch 100, Loss: 0.6255\n",
            "Epoch 10, Batch 200, Loss: 0.6283\n",
            "Epoch 10, Batch 300, Loss: 0.6416\n",
            "Epoch 11, Batch 100, Loss: 0.5966\n",
            "Epoch 11, Batch 200, Loss: 0.6031\n",
            "Epoch 11, Batch 300, Loss: 0.6045\n",
            "Epoch 12, Batch 100, Loss: 0.5862\n",
            "Epoch 12, Batch 200, Loss: 0.5835\n",
            "Epoch 12, Batch 300, Loss: 0.5903\n",
            "Epoch 13, Batch 100, Loss: 0.5481\n",
            "Epoch 13, Batch 200, Loss: 0.5652\n",
            "Epoch 13, Batch 300, Loss: 0.5700\n",
            "Epoch 14, Batch 100, Loss: 0.5350\n",
            "Epoch 14, Batch 200, Loss: 0.5487\n",
            "Epoch 14, Batch 300, Loss: 0.5661\n",
            "Epoch 15, Batch 100, Loss: 0.5355\n",
            "Epoch 15, Batch 200, Loss: 0.5349\n",
            "Epoch 15, Batch 300, Loss: 0.5417\n",
            "Epoch 16, Batch 100, Loss: 0.5223\n",
            "Epoch 16, Batch 200, Loss: 0.5255\n",
            "Epoch 16, Batch 300, Loss: 0.5286\n",
            "Epoch 17, Batch 100, Loss: 0.5147\n",
            "Epoch 17, Batch 200, Loss: 0.5019\n",
            "Epoch 17, Batch 300, Loss: 0.5057\n",
            "Epoch 18, Batch 100, Loss: 0.5002\n",
            "Epoch 18, Batch 200, Loss: 0.4858\n",
            "Epoch 18, Batch 300, Loss: 0.5034\n",
            "Epoch 19, Batch 100, Loss: 0.4927\n",
            "Epoch 19, Batch 200, Loss: 0.4869\n",
            "Epoch 19, Batch 300, Loss: 0.4744\n",
            "Epoch 20, Batch 100, Loss: 0.4798\n",
            "Epoch 20, Batch 200, Loss: 0.4660\n",
            "Epoch 20, Batch 300, Loss: 0.4760\n",
            "Finished Training\n",
            "Accuracy: 79.54%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Binarization function with straight-through estimator (STE)\n",
        "class BinaryActivation(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.sign()  # Binarize activations (output -1 or 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input.abs() > 1] = 0  # Gradient clipping for out of -1, 1 range\n",
        "        return grad_input\n",
        "\n",
        "# Binary convolutional layer\n",
        "class BinaryConv2d(nn.Conv2d):\n",
        "    def forward(self, input):\n",
        "        binary_weight = BinaryActivation.apply(self.weight)  # Binarize weights\n",
        "        return F.conv2d(input, binary_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "#Basic block used in ResNet\n",
        "class BinaryBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BinaryBasicBlock, self).__init__()\n",
        "        self.conv1 = BinaryConv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = BinaryConv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                BinaryConv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "#ResNet-32 architecture\n",
        "class BinaryResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(BinaryResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = BinaryConv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# ResNet-32 configuration\n",
        "def BinaryResNet32():\n",
        "    return BinaryResNet(BinaryBasicBlock, [5, 5, 5])\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomCrop(32, padding=4),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, trainloader, criterion, optimizer, device, epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100:.4f}')\n",
        "                running_loss = 0.0\n",
        "    print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "def test_model(model, testloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Setting up the device, model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BinaryResNet32().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training and testing the model\n",
        "train_model(model, trainloader, criterion, optimizer, device, epochs=20)\n",
        "test_model(model, testloader, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Sorry for not following order!\n",
        "\n",
        "#Here  Resnet 32 along with Addernet layer  "
      ],
      "metadata": {
        "id": "ctD1Os-nAv1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Function\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "\n",
        "# Define adder2d function and class\n",
        "def adder2d_function(X, W, stride=1, padding=0):\n",
        "    n_filters, d_filter, h_filter, w_filter = W.size()\n",
        "    n_x, d_x, h_x, w_x = X.size()\n",
        "\n",
        "    h_out = (h_x - h_filter + 2 * padding) / stride + 1\n",
        "    w_out = (w_x - w_filter + 2 * padding) / stride + 1\n",
        "\n",
        "    h_out, w_out = int(h_out), int(w_out)\n",
        "    X_col = torch.nn.functional.unfold(X.view(1, -1, h_x, w_x), h_filter, dilation=1, padding=padding, stride=stride).view(n_x, -1, h_out*w_out)\n",
        "    X_col = X_col.permute(1, 2, 0).contiguous().view(X_col.size(1), -1)\n",
        "    W_col = W.view(n_filters, -1)\n",
        "\n",
        "    out = adder.apply(W_col, X_col)\n",
        "\n",
        "    out = out.view(n_filters, h_out, w_out, n_x)\n",
        "    out = out.permute(3, 0, 1, 2).contiguous()\n",
        "\n",
        "    return out\n",
        "\n",
        "class adder(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, W_col, X_col):\n",
        "        ctx.save_for_backward(W_col, X_col)\n",
        "        output = -(W_col.unsqueeze(2) - X_col.unsqueeze(0)).abs().sum(1)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        W_col, X_col = ctx.saved_tensors\n",
        "        grad_W_col = ((X_col.unsqueeze(0) - W_col.unsqueeze(2)) * grad_output.unsqueeze(1)).sum(2)\n",
        "        grad_W_col = grad_W_col / grad_W_col.norm(p=2).clamp(min=1e-12) * math.sqrt(W_col.size(1) * W_col.size(0)) / 5\n",
        "        grad_X_col = (-(X_col.unsqueeze(0) - W_col.unsqueeze(2)).clamp(-1, 1) * grad_output.unsqueeze(1)).sum(0)\n",
        "\n",
        "        return grad_W_col, grad_X_col\n",
        "\n",
        "class adder2d(nn.Module):\n",
        "    def __init__(self, input_channel, output_channel, kernel_size, stride=1, padding=0, bias=False):\n",
        "        super(adder2d, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.input_channel = input_channel\n",
        "        self.output_channel = output_channel\n",
        "        self.kernel_size = kernel_size\n",
        "        self.adder = torch.nn.Parameter(nn.init.normal_(torch.randn(output_channel, input_channel, kernel_size, kernel_size)))\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.b = torch.nn.Parameter(nn.init.uniform_(torch.zeros(output_channel)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = adder2d_function(x, self.adder, self.stride, self.padding)\n",
        "        if self.bias:\n",
        "            output += self.b.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Basic Block for ResNet-32\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = adder2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = adder2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                adder2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define ResNet-32 Model\n",
        "class ResNet32(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet32, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = adder2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet32(BasicBlock, [5, 5, 5]).to(device)\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 4\n",
        "\n",
        "# Training function\n",
        "def train_model():\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Clear previous gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights using gradients\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
        "\n",
        "# Testing function\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # No gradient calculation in evaluation\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "# Train the model\n",
        "train_model()\n",
        "\n",
        "# Test the model\n",
        "test_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5a1463-4987-4a81-bad0-ceb849a964ee",
        "id": "BEHKcPhGttm1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:05<00:00, 29878493.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4ppBLFUq4rD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQkjrKCDLp2n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFsuaUfpLpiu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBhxUaTpLpg7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyrryuWiLpcc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmebc0LpLpat"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI0gMJLloswVMp6DZZ9MBD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}